{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/DATA/kumar156/YOLO-v7/yolov7\n"
     ]
    }
   ],
   "source": [
    "%cd yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', no_trace=False, nosave=False, project='runs/detect', save_conf=False, save_txt=False, source='Number-plate/test', update=False, view_img=False, weights=['weights/Trained_200.pt'])\n",
      "YOLOR ðŸš€ v0.1-107-g44d8ab4 torch 1.10.1+cu102 CUDA:0 (GeForce GTX 1080 Ti, 11178.5MB)\n",
      "\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n",
      "/DATA/kumar156/.local/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      "2 Number Plates, Done. (18.2ms) Inference, (2.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/10_DI-(-50).jpg\n",
      "2 Number Plates, Done. (18.3ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/11_DI-(-60).jpg\n",
      "2 Number Plates, Done. (18.3ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/12_DI-(-70).jpg\n",
      "2 Number Plates, Done. (18.3ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/13_DI-(-80).jpg\n",
      "2 Number Plates, Done. (18.3ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/14_MB-Angle25-Dist10.jpg\n",
      "2 Number Plates, Done. (18.3ms) Inference, (1.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/15_MB-Angle25-Dist20.jpg\n",
      "2 Number Plates, Done. (18.3ms) Inference, (1.3ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/16_MB-Angle25-Dist22.jpg\n",
      "2 Number Plates, Done. (18.4ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/17_MB-Angle25-Dist25.jpg\n",
      "1 Number Plate, Done. (18.4ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/18_ML-0.jpg\n",
      "1 Number Plate, Done. (18.3ms) Inference, (1.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/19_ML-45.jpg\n",
      "2 Number Plates, Done. (18.5ms) Inference, (1.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/1_BASE-0.jpg\n",
      "Done. (18.3ms) Inference, (0.3ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/20_ML-55.jpg\n",
      "2 Number Plates, Done. (18.3ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/21_(2400, 1080).jpg\n",
      "2 Number Plates, Done. (18.2ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/22_(2000, 900).jpg\n",
      "2 Number Plates, Done. (18.3ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/23_(1600, 720).jpg\n",
      "2 Number Plates, Done. (18.2ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/24_(1200, 540).jpg\n",
      "2 Number Plates, Done. (18.2ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/25_(800, 360).jpg\n",
      "1 Number Plate, Done. (18.3ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2_BASE-45.jpg\n",
      "2 Number Plates, Done. (21.4ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__08032010167.jpg\n",
      "1 Number Plate, Done. (21.8ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__1393707_10201643930673401_871708935_n.jpg\n",
      "1 Number Plate, Done. (18.5ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__149499_451599187886_713182886_5608668_7574952_n.jpg\n",
      "1 Number Plate, Done. (17.2ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__18bhrNUMBER_4c.jpg\n",
      "2 Number Plates, Done. (16.1ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__1958184_10201927264854597_141700995843809950_n.jpg\n",
      "1 Number Plate, Done. (17.2ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__20. Rearview.jpg\n",
      "1 Number Plate, Done. (17.9ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__200820134122.jpg\n",
      "1 Number Plate, Done. (18.4ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__20811b8eb4ccfadbb0391923bb225149.jpg\n",
      "1 Number Plate, Done. (17.2ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__33.jpg\n",
      "2 Number Plates, Done. (20.1ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__3714f0c9f0b0510a37553c45127dffe7.jpg\n",
      "2 Number Plates, Done. (21.4ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__3c1b8cf4d43f8371d01461e216205d30.jpg\n",
      "2 Number Plates, Done. (20.1ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__406113_258389320943385_435278228_n.jpg\n",
      "2 Number Plates, Done. (17.9ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__5228663371_f771e435b3_b.jpg\n",
      "1 Number Plate, Done. (16.1ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__61158933.jpg\n",
      "1 Number Plate, Done. (15.7ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__63210919.jpg\n",
      "2 Number Plates, Done. (17.9ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__70393894.jpg\n",
      "1 Number Plate, Done. (21.4ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__930bd010089d3b397b8d710422b53d13.jpg\n",
      "1 Number Plate, Done. (17.3ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__AP CM Jagan car.jpg\n",
      "1 Number Plate, Done. (17.9ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__C68MadbWsAEMt23.jpg\n",
      "1 Number Plate, Done. (16.8ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__CB09TRAFFICPOLICE.jpg\n",
      "3 Number Plates, Done. (17.9ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__CDL2W0FVAAAPIm7.jpg\n",
      "1 Number Plate, Done. (17.9ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__CfctwQaUsAA_ug2.jpg\n",
      "2 Number Plates, Done. (21.4ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__a95c73144cff69bc5f658e9af9918f58.jpg\n",
      "1 Number Plate, Done. (19.6ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__aL3eXlk.jpg\n",
      "1 Number Plate, Done. (16.1ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__aa-Cover-spd7dvlhod1a6chmerjqs2u8s6-20171118071436.Medi.jpg\n",
      "2 Number Plates, Done. (17.9ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__bdc574ae0edc2a9410c2f86427827fd4.jpg\n",
      "1 Number Plate, Done. (16.1ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__bjp_car.jpg\n",
      "3 Number Plates, Done. (16.7ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__car.jpg\n",
      "1 Number Plate, Done. (16.1ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/2__1__carwithfancydisplay.jpg\n",
      "1 Number Plate, Done. (14.6ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/3_BASE-55.jpg\n",
      "2 Number Plates, Done. (17.3ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/3__20180813013844_EVs-to-get-green-plates.jpg\n",
      "1 Number Plate, Done. (18.4ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/3__255359248.jpg\n",
      "2 Number Plates, Done. (17.9ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/3__41622166662_02b699b417_b.jpg\n",
      "2 Number Plates, Done. (18.0ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/3__A8.jpg\n",
      "1 Number Plate, Done. (18.0ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/3__a-car-with-fancy-number-9999-in-hyderabadindia-PKEFRC.jpg\n",
      "1 Number Plate, Done. (20.1ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/3__about-1.jpg\n",
      "1 Number Plate, Done. (17.9ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/3__adyar-call-taxi-adyar-chennai-call-taxi-services-42vpj1f.jpg\n",
      "1 Number Plate, Done. (21.4ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/3__amaze.jpg\n",
      "3 Number Plates, Done. (18.5ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/3__attitude.jpg\n",
      "1 Number Plate, Done. (18.0ms) Inference, (1.0ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/3__auto-rickshaw-jaipur-rajasthan-india-BXFN4G.jpg\n",
      "3 Number Plates, Done. (17.9ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/3__back-indian-truck-parked-image-its-vividly-colored-message-horn-please-india-all-trucks-have-41308734.jpg\n",
      "1 Number Plate, Done. (17.2ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/3__bangalore-man-pays-rs-31-lakhs-number-plate-india-license-porsche-718-boxster.jpg\n",
      "1 Number Plate, Done. (20.1ms) Inference, (0.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/3__bhopal-city-link-ltd-bhopal-bhopal-bus-services-3q3okku.jpg\n",
      "1 Number Plate, Done. (14.6ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/4_BASE-70.jpg\n",
      "1 Number Plate, Done. (14.7ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/5_TILT-20.jpg\n",
      "1 Number Plate, Done. (14.7ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/6_TILT-25.jpg\n",
      "1 Number Plate, Done. (15.0ms) Inference, (1.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/7_TILT-30.jpg\n",
      "1 Number Plate, Done. (14.7ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/8_TILT-40.jpg\n",
      "2 Number Plates, Done. (14.8ms) Inference, (1.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp9/9_DI-(-25).jpg\n",
      "Done. (10.816s)\n"
     ]
    }
   ],
   "source": [
    "#!python3 detect.py --weights runs/train/exp10/weights/best.pt --conf 0.3 --source Number-plate/test\n",
    "!python3 detect.py --weights weights/Trained_200.pt --conf 0.3 --source Number-plate/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('annotated_data/train/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('yolov7')\n",
    "\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "from numpy import random\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import LoadStreams, LoadImages\n",
    "from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n",
    "    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n",
    "from utils.plots import plot_one_box\n",
    "from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel\n",
    "\n",
    "\n",
    "def letterbox(img, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):\n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = img.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better test mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    ratio = r, r  # width, height ratios\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "    elif scaleFill:  # stretch\n",
    "        dw, dh = 0.0, 0.0\n",
    "        new_unpad = (new_shape[1], new_shape[0])\n",
    "        ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return img, ratio, (dw, dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_filter = None  #You can give list of classes to filter by name, Be happy you don't have to put class number. ['train','person' ]\n",
    "\n",
    "\n",
    "opt  = {\n",
    "    \n",
    "    \"weights\": \"weights/final.pt\", # Path to weights file default weights are for nano model\n",
    "    \"yaml\"   : \"Number-plate/data.yaml\",\n",
    "    \"img-size\": 640, # default image size\n",
    "    \"conf-thres\": 0.1, # confidence threshold for inference.\n",
    "    \"iou-thres\" : 0.45, # NMS IoU threshold for inference.\n",
    "    \"device\" : '3',  # device to run our model i.e. 0 or 0,1,2,3 or cpu\n",
    "    \"classes\" : classes_to_filter  # list of classes to filter or None\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "YOLOR ðŸš€ v0.1-107-g44d8ab4 torch 1.10.1+cu102 CUDA:3 (GeForce GTX 1080 Ti, 11178.5MB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DATA/kumar156/.local/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n",
      "1/533 frames processed\n",
      "2/533 frames processed\n",
      "3/533 frames processed\n",
      "4/533 frames processed\n",
      "5/533 frames processed\n",
      "6/533 frames processed\n",
      "7/533 frames processed\n",
      "8/533 frames processed\n",
      "9/533 frames processed\n",
      "10/533 frames processed\n",
      "11/533 frames processed\n",
      "12/533 frames processed\n",
      "13/533 frames processed\n",
      "14/533 frames processed\n",
      "15/533 frames processed\n",
      "16/533 frames processed\n",
      "17/533 frames processed\n",
      "18/533 frames processed\n",
      "19/533 frames processed\n",
      "20/533 frames processed\n",
      "21/533 frames processed\n",
      "22/533 frames processed\n",
      "23/533 frames processed\n",
      "24/533 frames processed\n",
      "25/533 frames processed\n",
      "26/533 frames processed\n",
      "27/533 frames processed\n",
      "28/533 frames processed\n",
      "29/533 frames processed\n",
      "30/533 frames processed\n",
      "31/533 frames processed\n",
      "32/533 frames processed\n",
      "33/533 frames processed\n",
      "34/533 frames processed\n",
      "35/533 frames processed\n",
      "36/533 frames processed\n",
      "37/533 frames processed\n",
      "38/533 frames processed\n",
      "39/533 frames processed\n",
      "40/533 frames processed\n",
      "41/533 frames processed\n",
      "42/533 frames processed\n",
      "43/533 frames processed\n",
      "44/533 frames processed\n",
      "45/533 frames processed\n",
      "46/533 frames processed\n",
      "47/533 frames processed\n",
      "48/533 frames processed\n",
      "49/533 frames processed\n",
      "50/533 frames processed\n",
      "51/533 frames processed\n",
      "52/533 frames processed\n",
      "53/533 frames processed\n",
      "54/533 frames processed\n",
      "55/533 frames processed\n",
      "56/533 frames processed\n",
      "57/533 frames processed\n",
      "58/533 frames processed\n",
      "59/533 frames processed\n",
      "60/533 frames processed\n",
      "61/533 frames processed\n",
      "62/533 frames processed\n",
      "63/533 frames processed\n",
      "64/533 frames processed\n",
      "65/533 frames processed\n",
      "66/533 frames processed\n",
      "67/533 frames processed\n",
      "68/533 frames processed\n",
      "69/533 frames processed\n",
      "70/533 frames processed\n",
      "71/533 frames processed\n",
      "72/533 frames processed\n",
      "73/533 frames processed\n",
      "74/533 frames processed\n",
      "75/533 frames processed\n",
      "76/533 frames processed\n",
      "77/533 frames processed\n",
      "78/533 frames processed\n",
      "79/533 frames processed\n",
      "80/533 frames processed\n",
      "81/533 frames processed\n",
      "82/533 frames processed\n",
      "83/533 frames processed\n",
      "84/533 frames processed\n",
      "85/533 frames processed\n",
      "86/533 frames processed\n",
      "87/533 frames processed\n",
      "88/533 frames processed\n",
      "89/533 frames processed\n",
      "90/533 frames processed\n",
      "91/533 frames processed\n",
      "92/533 frames processed\n",
      "93/533 frames processed\n",
      "94/533 frames processed\n",
      "95/533 frames processed\n",
      "96/533 frames processed\n",
      "97/533 frames processed\n",
      "98/533 frames processed\n",
      "99/533 frames processed\n",
      "100/533 frames processed\n",
      "101/533 frames processed\n",
      "102/533 frames processed\n",
      "103/533 frames processed\n",
      "104/533 frames processed\n",
      "105/533 frames processed\n",
      "106/533 frames processed\n",
      "107/533 frames processed\n",
      "108/533 frames processed\n",
      "109/533 frames processed\n",
      "110/533 frames processed\n",
      "111/533 frames processed\n",
      "112/533 frames processed\n",
      "113/533 frames processed\n",
      "114/533 frames processed\n",
      "115/533 frames processed\n",
      "116/533 frames processed\n",
      "117/533 frames processed\n",
      "118/533 frames processed\n",
      "119/533 frames processed\n",
      "120/533 frames processed\n",
      "121/533 frames processed\n",
      "122/533 frames processed\n",
      "123/533 frames processed\n",
      "124/533 frames processed\n",
      "125/533 frames processed\n",
      "126/533 frames processed\n",
      "127/533 frames processed\n",
      "128/533 frames processed\n",
      "129/533 frames processed\n",
      "130/533 frames processed\n",
      "131/533 frames processed\n",
      "132/533 frames processed\n",
      "133/533 frames processed\n",
      "134/533 frames processed\n",
      "135/533 frames processed\n",
      "136/533 frames processed\n",
      "137/533 frames processed\n",
      "138/533 frames processed\n",
      "139/533 frames processed\n",
      "140/533 frames processed\n",
      "141/533 frames processed\n",
      "142/533 frames processed\n",
      "143/533 frames processed\n",
      "144/533 frames processed\n",
      "145/533 frames processed\n",
      "146/533 frames processed\n",
      "147/533 frames processed\n",
      "148/533 frames processed\n",
      "149/533 frames processed\n",
      "150/533 frames processed\n",
      "151/533 frames processed\n",
      "152/533 frames processed\n",
      "153/533 frames processed\n",
      "154/533 frames processed\n",
      "155/533 frames processed\n",
      "156/533 frames processed\n",
      "157/533 frames processed\n",
      "158/533 frames processed\n",
      "159/533 frames processed\n",
      "160/533 frames processed\n",
      "161/533 frames processed\n",
      "162/533 frames processed\n",
      "163/533 frames processed\n",
      "164/533 frames processed\n",
      "165/533 frames processed\n",
      "166/533 frames processed\n",
      "167/533 frames processed\n",
      "168/533 frames processed\n",
      "169/533 frames processed\n",
      "170/533 frames processed\n",
      "171/533 frames processed\n",
      "172/533 frames processed\n",
      "173/533 frames processed\n",
      "174/533 frames processed\n",
      "175/533 frames processed\n",
      "176/533 frames processed\n",
      "177/533 frames processed\n",
      "178/533 frames processed\n",
      "179/533 frames processed\n",
      "180/533 frames processed\n",
      "181/533 frames processed\n",
      "182/533 frames processed\n",
      "183/533 frames processed\n",
      "184/533 frames processed\n",
      "185/533 frames processed\n",
      "186/533 frames processed\n",
      "187/533 frames processed\n",
      "188/533 frames processed\n",
      "189/533 frames processed\n",
      "190/533 frames processed\n",
      "191/533 frames processed\n",
      "192/533 frames processed\n",
      "193/533 frames processed\n",
      "194/533 frames processed\n",
      "195/533 frames processed\n",
      "196/533 frames processed\n",
      "197/533 frames processed\n",
      "198/533 frames processed\n",
      "199/533 frames processed\n",
      "200/533 frames processed\n",
      "201/533 frames processed\n",
      "202/533 frames processed\n",
      "203/533 frames processed\n",
      "204/533 frames processed\n",
      "205/533 frames processed\n",
      "206/533 frames processed\n",
      "207/533 frames processed\n",
      "208/533 frames processed\n",
      "209/533 frames processed\n",
      "210/533 frames processed\n",
      "211/533 frames processed\n",
      "212/533 frames processed\n",
      "213/533 frames processed\n",
      "214/533 frames processed\n",
      "215/533 frames processed\n",
      "216/533 frames processed\n",
      "217/533 frames processed\n",
      "218/533 frames processed\n",
      "219/533 frames processed\n",
      "220/533 frames processed\n",
      "221/533 frames processed\n",
      "222/533 frames processed\n",
      "223/533 frames processed\n",
      "224/533 frames processed\n",
      "225/533 frames processed\n",
      "226/533 frames processed\n",
      "227/533 frames processed\n",
      "228/533 frames processed\n",
      "229/533 frames processed\n",
      "230/533 frames processed\n",
      "231/533 frames processed\n",
      "232/533 frames processed\n",
      "233/533 frames processed\n",
      "234/533 frames processed\n",
      "235/533 frames processed\n",
      "236/533 frames processed\n",
      "237/533 frames processed\n",
      "238/533 frames processed\n",
      "239/533 frames processed\n",
      "240/533 frames processed\n",
      "241/533 frames processed\n",
      "242/533 frames processed\n",
      "243/533 frames processed\n",
      "244/533 frames processed\n",
      "245/533 frames processed\n",
      "246/533 frames processed\n",
      "247/533 frames processed\n",
      "248/533 frames processed\n",
      "249/533 frames processed\n",
      "250/533 frames processed\n",
      "251/533 frames processed\n",
      "252/533 frames processed\n",
      "253/533 frames processed\n",
      "254/533 frames processed\n",
      "255/533 frames processed\n",
      "256/533 frames processed\n",
      "257/533 frames processed\n",
      "258/533 frames processed\n",
      "259/533 frames processed\n",
      "260/533 frames processed\n",
      "261/533 frames processed\n",
      "262/533 frames processed\n",
      "263/533 frames processed\n",
      "264/533 frames processed\n",
      "265/533 frames processed\n",
      "266/533 frames processed\n",
      "267/533 frames processed\n",
      "268/533 frames processed\n",
      "269/533 frames processed\n",
      "270/533 frames processed\n",
      "271/533 frames processed\n",
      "272/533 frames processed\n",
      "273/533 frames processed\n",
      "274/533 frames processed\n",
      "275/533 frames processed\n",
      "276/533 frames processed\n",
      "277/533 frames processed\n",
      "278/533 frames processed\n",
      "279/533 frames processed\n",
      "280/533 frames processed\n",
      "281/533 frames processed\n",
      "282/533 frames processed\n",
      "283/533 frames processed\n",
      "284/533 frames processed\n",
      "285/533 frames processed\n",
      "286/533 frames processed\n",
      "287/533 frames processed\n",
      "288/533 frames processed\n",
      "289/533 frames processed\n",
      "290/533 frames processed\n",
      "291/533 frames processed\n",
      "292/533 frames processed\n",
      "293/533 frames processed\n",
      "294/533 frames processed\n",
      "295/533 frames processed\n",
      "296/533 frames processed\n",
      "297/533 frames processed\n",
      "298/533 frames processed\n",
      "299/533 frames processed\n",
      "300/533 frames processed\n",
      "301/533 frames processed\n",
      "302/533 frames processed\n",
      "303/533 frames processed\n",
      "304/533 frames processed\n",
      "305/533 frames processed\n",
      "306/533 frames processed\n",
      "307/533 frames processed\n",
      "308/533 frames processed\n",
      "309/533 frames processed\n",
      "310/533 frames processed\n",
      "311/533 frames processed\n",
      "312/533 frames processed\n",
      "313/533 frames processed\n",
      "314/533 frames processed\n",
      "315/533 frames processed\n",
      "316/533 frames processed\n",
      "317/533 frames processed\n",
      "318/533 frames processed\n",
      "319/533 frames processed\n",
      "320/533 frames processed\n",
      "321/533 frames processed\n",
      "322/533 frames processed\n",
      "323/533 frames processed\n",
      "324/533 frames processed\n",
      "325/533 frames processed\n",
      "326/533 frames processed\n",
      "327/533 frames processed\n",
      "328/533 frames processed\n",
      "329/533 frames processed\n",
      "330/533 frames processed\n",
      "331/533 frames processed\n",
      "332/533 frames processed\n",
      "333/533 frames processed\n",
      "334/533 frames processed\n",
      "335/533 frames processed\n",
      "336/533 frames processed\n",
      "337/533 frames processed\n",
      "338/533 frames processed\n",
      "339/533 frames processed\n",
      "340/533 frames processed\n",
      "341/533 frames processed\n",
      "342/533 frames processed\n",
      "343/533 frames processed\n",
      "344/533 frames processed\n",
      "345/533 frames processed\n",
      "346/533 frames processed\n",
      "347/533 frames processed\n",
      "348/533 frames processed\n",
      "349/533 frames processed\n",
      "350/533 frames processed\n",
      "351/533 frames processed\n",
      "352/533 frames processed\n",
      "353/533 frames processed\n",
      "354/533 frames processed\n",
      "355/533 frames processed\n",
      "356/533 frames processed\n",
      "357/533 frames processed\n",
      "358/533 frames processed\n",
      "359/533 frames processed\n",
      "360/533 frames processed\n",
      "361/533 frames processed\n",
      "362/533 frames processed\n",
      "363/533 frames processed\n",
      "364/533 frames processed\n",
      "365/533 frames processed\n",
      "366/533 frames processed\n",
      "367/533 frames processed\n",
      "368/533 frames processed\n",
      "369/533 frames processed\n",
      "370/533 frames processed\n",
      "371/533 frames processed\n",
      "372/533 frames processed\n",
      "373/533 frames processed\n",
      "374/533 frames processed\n",
      "375/533 frames processed\n",
      "376/533 frames processed\n",
      "377/533 frames processed\n",
      "378/533 frames processed\n",
      "379/533 frames processed\n",
      "380/533 frames processed\n",
      "381/533 frames processed\n",
      "382/533 frames processed\n",
      "383/533 frames processed\n",
      "384/533 frames processed\n",
      "385/533 frames processed\n",
      "386/533 frames processed\n",
      "387/533 frames processed\n",
      "388/533 frames processed\n",
      "389/533 frames processed\n",
      "390/533 frames processed\n",
      "391/533 frames processed\n",
      "392/533 frames processed\n",
      "393/533 frames processed\n",
      "394/533 frames processed\n",
      "395/533 frames processed\n",
      "396/533 frames processed\n",
      "397/533 frames processed\n",
      "398/533 frames processed\n",
      "399/533 frames processed\n",
      "400/533 frames processed\n",
      "401/533 frames processed\n",
      "402/533 frames processed\n",
      "403/533 frames processed\n",
      "404/533 frames processed\n",
      "405/533 frames processed\n",
      "406/533 frames processed\n",
      "407/533 frames processed\n",
      "408/533 frames processed\n",
      "409/533 frames processed\n",
      "410/533 frames processed\n",
      "411/533 frames processed\n",
      "412/533 frames processed\n",
      "413/533 frames processed\n",
      "414/533 frames processed\n",
      "415/533 frames processed\n",
      "416/533 frames processed\n",
      "417/533 frames processed\n",
      "418/533 frames processed\n",
      "419/533 frames processed\n",
      "420/533 frames processed\n",
      "421/533 frames processed\n",
      "422/533 frames processed\n",
      "423/533 frames processed\n",
      "424/533 frames processed\n",
      "425/533 frames processed\n",
      "426/533 frames processed\n",
      "427/533 frames processed\n",
      "428/533 frames processed\n",
      "429/533 frames processed\n",
      "430/533 frames processed\n",
      "431/533 frames processed\n",
      "432/533 frames processed\n",
      "433/533 frames processed\n",
      "434/533 frames processed\n",
      "435/533 frames processed\n",
      "436/533 frames processed\n",
      "437/533 frames processed\n",
      "438/533 frames processed\n",
      "439/533 frames processed\n",
      "440/533 frames processed\n",
      "441/533 frames processed\n",
      "442/533 frames processed\n",
      "443/533 frames processed\n",
      "444/533 frames processed\n",
      "445/533 frames processed\n",
      "446/533 frames processed\n",
      "447/533 frames processed\n",
      "448/533 frames processed\n",
      "449/533 frames processed\n",
      "450/533 frames processed\n",
      "451/533 frames processed\n",
      "452/533 frames processed\n",
      "453/533 frames processed\n",
      "454/533 frames processed\n",
      "455/533 frames processed\n",
      "456/533 frames processed\n",
      "457/533 frames processed\n",
      "458/533 frames processed\n",
      "459/533 frames processed\n",
      "460/533 frames processed\n",
      "461/533 frames processed\n",
      "462/533 frames processed\n",
      "463/533 frames processed\n",
      "464/533 frames processed\n",
      "465/533 frames processed\n",
      "466/533 frames processed\n",
      "467/533 frames processed\n",
      "468/533 frames processed\n",
      "469/533 frames processed\n",
      "470/533 frames processed\n",
      "471/533 frames processed\n",
      "472/533 frames processed\n",
      "473/533 frames processed\n",
      "474/533 frames processed\n",
      "475/533 frames processed\n",
      "476/533 frames processed\n",
      "477/533 frames processed\n",
      "478/533 frames processed\n",
      "479/533 frames processed\n",
      "480/533 frames processed\n",
      "481/533 frames processed\n",
      "482/533 frames processed\n",
      "483/533 frames processed\n",
      "484/533 frames processed\n",
      "485/533 frames processed\n",
      "486/533 frames processed\n",
      "487/533 frames processed\n",
      "488/533 frames processed\n",
      "489/533 frames processed\n",
      "490/533 frames processed\n",
      "491/533 frames processed\n",
      "492/533 frames processed\n",
      "493/533 frames processed\n",
      "494/533 frames processed\n",
      "495/533 frames processed\n",
      "496/533 frames processed\n",
      "497/533 frames processed\n",
      "498/533 frames processed\n",
      "499/533 frames processed\n",
      "500/533 frames processed\n",
      "501/533 frames processed\n",
      "502/533 frames processed\n",
      "503/533 frames processed\n",
      "504/533 frames processed\n",
      "505/533 frames processed\n",
      "506/533 frames processed\n",
      "507/533 frames processed\n",
      "508/533 frames processed\n",
      "509/533 frames processed\n",
      "510/533 frames processed\n",
      "511/533 frames processed\n",
      "512/533 frames processed\n",
      "513/533 frames processed\n",
      "514/533 frames processed\n",
      "515/533 frames processed\n",
      "516/533 frames processed\n",
      "517/533 frames processed\n",
      "518/533 frames processed\n",
      "519/533 frames processed\n",
      "520/533 frames processed\n",
      "521/533 frames processed\n",
      "522/533 frames processed\n",
      "523/533 frames processed\n",
      "524/533 frames processed\n",
      "525/533 frames processed\n",
      "526/533 frames processed\n",
      "527/533 frames processed\n",
      "528/533 frames processed\n",
      "529/533 frames processed\n",
      "530/533 frames processed\n",
      "531/533 frames processed\n"
     ]
    }
   ],
   "source": [
    "video_path = \"Number-plate/ANPR-video/B16_cut.mp4\"\n",
    "# Initializing video object\n",
    "video = cv2.VideoCapture(video_path)\n",
    "\n",
    "\n",
    "#Video information\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "w = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "nframes = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Initialzing object for writing video output\n",
    "output = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'DIVX'),fps , (w,h))\n",
    "torch.cuda.empty_cache()\n",
    "# Initializing model and setting it for inference\n",
    "with torch.no_grad():\n",
    "  weights, imgsz = opt['weights'], opt['img-size']\n",
    "  set_logging()\n",
    "  device = select_device(opt['device'])\n",
    "  half = device.type != 'cpu'\n",
    "  model = attempt_load(weights, map_location=device)  # load FP32 model\n",
    "  stride = int(model.stride.max())  # model stride\n",
    "  imgsz = check_img_size(imgsz, s=stride)  # check img_size\n",
    "  if half:\n",
    "    model.half()\n",
    "\n",
    "  names = model.module.names if hasattr(model, 'module') else model.names\n",
    "  colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
    "  if device.type != 'cpu':\n",
    "    model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))\n",
    "\n",
    "  classes = None\n",
    "  if opt['classes']:\n",
    "    classes = []\n",
    "    for class_name in opt['classes']:\n",
    "      classes.append(opt['classes'].index(class_name))\n",
    "\n",
    "  for j in range(nframes):\n",
    "\n",
    "      ret, img0 = video.read()\n",
    "      if ret:\n",
    "        img = letterbox(img0, imgsz, stride=stride)[0]\n",
    "        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
    "        img = np.ascontiguousarray(img)\n",
    "        img = torch.from_numpy(img).to(device)\n",
    "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if img.ndimension() == 3:\n",
    "          img = img.unsqueeze(0)\n",
    "\n",
    "        # Inference\n",
    "        t1 = time_synchronized()\n",
    "        pred = model(img, augment= False)[0]\n",
    "\n",
    "        \n",
    "        pred = non_max_suppression(pred, opt['conf-thres'], opt['iou-thres'], classes= classes, agnostic= False)\n",
    "        t2 = time_synchronized()\n",
    "        for i, det in enumerate(pred):\n",
    "          s = ''\n",
    "          s += '%gx%g ' % img.shape[2:]  # print string\n",
    "          gn = torch.tensor(img0.shape)[[1, 0, 1, 0]]\n",
    "          if len(det):\n",
    "            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()\n",
    "\n",
    "            for c in det[:, -1].unique():\n",
    "              n = (det[:, -1] == c).sum()  # detections per class\n",
    "              s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "    \n",
    "            for *xyxy, conf, cls in reversed(det):\n",
    "\n",
    "              label = f'{names[int(cls)]} {conf:.2f}'\n",
    "              plot_one_box(xyxy, img0, label=label, color=colors[int(cls)], line_thickness=3)\n",
    "        \n",
    "        print(f\"{j+1}/{nframes} frames processed\")\n",
    "        output.write(img0)\n",
    "      else:\n",
    "        break\n",
    "    \n",
    "\n",
    "output.release()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: 1: ffmpeg: not found\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'result_compressed.mp4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37924/3894578058.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Show video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmp4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompressed_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mdata_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data:video/mp4;base64,\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb64encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m HTML(\"\"\"\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'result_compressed.mp4'"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "import os\n",
    "\n",
    "# Input video path\n",
    "save_path = 'output.mp4'\n",
    "\n",
    "# Compressed video path\n",
    "compressed_path = 'result_compressed.mp4'\n",
    "\n",
    "os.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\n",
    "\n",
    "# Show video\n",
    "mp4 = open(compressed_path,'rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(\"\"\"\n",
    "<video width=400 controls>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\" % data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
